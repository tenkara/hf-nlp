{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Github issues corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\raj\\repos\\hf-nlp\\.venv\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\raj\\repos\\hf-nlp\\.venv\\lib\\site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\raj\\repos\\hf-nlp\\.venv\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\raj\\repos\\hf-nlp\\.venv\\lib\\site-packages (from requests) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\raj\\repos\\hf-nlp\\.venv\\lib\\site-packages (from requests) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "# install requests package if not installed\n",
    "! pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests package\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the github issues from dataset repository\n",
    "# first let's get the first issue on first page\n",
    "url = 'https://api.github.com/repos/huggingface/datasets/issues/1'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://api.github.com/repos/huggingface/datasets/issues/1',\n",
       " 'repository_url': 'https://api.github.com/repos/huggingface/datasets',\n",
       " 'labels_url': 'https://api.github.com/repos/huggingface/datasets/issues/1/labels{/name}',\n",
       " 'comments_url': 'https://api.github.com/repos/huggingface/datasets/issues/1/comments',\n",
       " 'events_url': 'https://api.github.com/repos/huggingface/datasets/issues/1/events',\n",
       " 'html_url': 'https://github.com/huggingface/datasets/pull/1',\n",
       " 'id': 599457467,\n",
       " 'node_id': 'MDExOlB1bGxSZXF1ZXN0NDAzMDk1NDYw',\n",
       " 'number': 1,\n",
       " 'title': 'changing nlp.bool to nlp.bool_',\n",
       " 'user': {'login': 'mariamabarham',\n",
       "  'id': 38249783,\n",
       "  'node_id': 'MDQ6VXNlcjM4MjQ5Nzgz',\n",
       "  'avatar_url': 'https://avatars.githubusercontent.com/u/38249783?v=4',\n",
       "  'gravatar_id': '',\n",
       "  'url': 'https://api.github.com/users/mariamabarham',\n",
       "  'html_url': 'https://github.com/mariamabarham',\n",
       "  'followers_url': 'https://api.github.com/users/mariamabarham/followers',\n",
       "  'following_url': 'https://api.github.com/users/mariamabarham/following{/other_user}',\n",
       "  'gists_url': 'https://api.github.com/users/mariamabarham/gists{/gist_id}',\n",
       "  'starred_url': 'https://api.github.com/users/mariamabarham/starred{/owner}{/repo}',\n",
       "  'subscriptions_url': 'https://api.github.com/users/mariamabarham/subscriptions',\n",
       "  'organizations_url': 'https://api.github.com/users/mariamabarham/orgs',\n",
       "  'repos_url': 'https://api.github.com/users/mariamabarham/repos',\n",
       "  'events_url': 'https://api.github.com/users/mariamabarham/events{/privacy}',\n",
       "  'received_events_url': 'https://api.github.com/users/mariamabarham/received_events',\n",
       "  'type': 'User',\n",
       "  'site_admin': False},\n",
       " 'labels': [],\n",
       " 'state': 'closed',\n",
       " 'locked': False,\n",
       " 'assignee': None,\n",
       " 'assignees': [],\n",
       " 'milestone': None,\n",
       " 'comments': 0,\n",
       " 'created_at': '2020-04-14T10:18:02Z',\n",
       " 'updated_at': '2022-10-04T09:31:40Z',\n",
       " 'closed_at': '2020-04-14T12:01:40Z',\n",
       " 'author_association': 'CONTRIBUTOR',\n",
       " 'active_lock_reason': None,\n",
       " 'draft': False,\n",
       " 'pull_request': {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/1',\n",
       "  'html_url': 'https://github.com/huggingface/datasets/pull/1',\n",
       "  'diff_url': 'https://github.com/huggingface/datasets/pull/1.diff',\n",
       "  'patch_url': 'https://github.com/huggingface/datasets/pull/1.patch',\n",
       "  'merged_at': '2020-04-14T12:01:40Z'},\n",
       " 'body': '',\n",
       " 'closed_by': {'login': 'thomwolf',\n",
       "  'id': 7353373,\n",
       "  'node_id': 'MDQ6VXNlcjczNTMzNzM=',\n",
       "  'avatar_url': 'https://avatars.githubusercontent.com/u/7353373?v=4',\n",
       "  'gravatar_id': '',\n",
       "  'url': 'https://api.github.com/users/thomwolf',\n",
       "  'html_url': 'https://github.com/thomwolf',\n",
       "  'followers_url': 'https://api.github.com/users/thomwolf/followers',\n",
       "  'following_url': 'https://api.github.com/users/thomwolf/following{/other_user}',\n",
       "  'gists_url': 'https://api.github.com/users/thomwolf/gists{/gist_id}',\n",
       "  'starred_url': 'https://api.github.com/users/thomwolf/starred{/owner}{/repo}',\n",
       "  'subscriptions_url': 'https://api.github.com/users/thomwolf/subscriptions',\n",
       "  'organizations_url': 'https://api.github.com/users/thomwolf/orgs',\n",
       "  'repos_url': 'https://api.github.com/users/thomwolf/repos',\n",
       "  'events_url': 'https://api.github.com/users/thomwolf/events{/privacy}',\n",
       "  'received_events_url': 'https://api.github.com/users/thomwolf/received_events',\n",
       "  'type': 'User',\n",
       "  'site_admin': False},\n",
       " 'reactions': {'url': 'https://api.github.com/repos/huggingface/datasets/issues/1/reactions',\n",
       "  'total_count': 0,\n",
       "  '+1': 0,\n",
       "  '-1': 0,\n",
       "  'laugh': 0,\n",
       "  'hooray': 0,\n",
       "  'confused': 0,\n",
       "  'heart': 0,\n",
       "  'rocket': 0,\n",
       "  'eyes': 0},\n",
       " 'timeline_url': 'https://api.github.com/repos/huggingface/datasets/issues/1/timeline',\n",
       " 'performed_via_github_app': None,\n",
       " 'state_reason': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\raj\\repos\\hf-nlp\\.venv\\lib\\site-packages (1.0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the github token from env file\n",
    "! pip install python-dotenv\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\n",
    "headers = {'Authorization': f'token {GITHUB_TOKEN}'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the github issues from dataset repository\n",
    "\n",
    "import time\n",
    "import math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get the github issues from dataset repository\n",
    "all_issues = [] # debugging\n",
    "\n",
    "def fetch_issues(\n",
    "        owner='huggingface',\n",
    "        repo='datasets',\n",
    "        num_issues=10_000,\n",
    "        rate_limit=5000,\n",
    "        issues_path=Path(\"../data\"),\n",
    "):\n",
    "    if not issues_path.is_dir():\n",
    "        issues_path.mkdir(exist_ok=True)\n",
    "\n",
    "    batch = []\n",
    "    # all_issues = []\n",
    "    per_page = 100 # number of issues to return per page\n",
    "    num_pages = math.ceil(num_issues / per_page) # number of pages to request\n",
    "    base_url = \"https://api.github.com/repos\"\n",
    "\n",
    "    for page in tqdm(range(1, num_pages)):\n",
    "        # Query with state=all to get both open and closed issues\n",
    "        query = f\"issues?page={page}&per_page={per_page}&state=all\"\n",
    "        issues = requests.get(f\"{base_url}/{owner}/{repo}/{query}\", headers=headers)\n",
    "        batch.extend(issues.json())\n",
    "\n",
    "        # if we reach the rate limit, save the batch and wait until we can make more requests\n",
    "        if len(batch) >= rate_limit and len(all_issues) < num_issues:\n",
    "            all_issues.extend(batch)\n",
    "            batch = [] # flush batch for next iteration\n",
    "            print(f\"Reached Github rate limit. Sleeping for 1 min...\")\n",
    "            time.sleep(60) # sleep for 1 minute \n",
    "\n",
    "    # save the remaining issues\n",
    "    all_issues.extend(batch)\n",
    "    df = pd.Dataframe.from_records(all_issues)\n",
    "    df.to_json(f\"{issues_path}/{repo}-issues.jsonl, orient='records', lines=True\")\n",
    "    print (f\"Downloaded all the issues for {repo}! Dataset saved at {issues_path}/{repo}-issues.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/99 [01:00<00:56,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached Github rate limit. Sleeping for 1 min...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [02:23<00:00,  1.45s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'Dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# fetch the issues from the dataset repository\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m fetch_issues()\n",
      "Cell \u001b[1;32mIn[18], line 35\u001b[0m, in \u001b[0;36mfetch_issues\u001b[1;34m(owner, repo, num_issues, rate_limit, issues_path)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39m# save the remaining issues\u001b[39;00m\n\u001b[0;32m     34\u001b[0m all_issues\u001b[39m.\u001b[39mextend(batch)\n\u001b[1;32m---> 35\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataframe\u001b[39m.\u001b[39mfrom_records(all_issues)\n\u001b[0;32m     36\u001b[0m df\u001b[39m.\u001b[39mto_json(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00missues_path\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mrepo\u001b[39m}\u001b[39;00m\u001b[39m-issues.jsonl, orient=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrecords\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, lines=True\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloaded all the issues for \u001b[39m\u001b[39m{\u001b[39;00mrepo\u001b[39m}\u001b[39;00m\u001b[39m! Dataset saved at \u001b[39m\u001b[39m{\u001b[39;00missues_path\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mrepo\u001b[39m}\u001b[39;00m\u001b[39m-issues.jsonl\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'Dataframe'"
     ]
    }
   ],
   "source": [
    "# fetch the issues from the dataset repository\n",
    "fetch_issues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5841"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_issues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>repository_url</th>\n",
       "      <th>labels_url</th>\n",
       "      <th>comments_url</th>\n",
       "      <th>events_url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>id</th>\n",
       "      <th>node_id</th>\n",
       "      <th>number</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>closed_at</th>\n",
       "      <th>author_association</th>\n",
       "      <th>active_lock_reason</th>\n",
       "      <th>body</th>\n",
       "      <th>reactions</th>\n",
       "      <th>timeline_url</th>\n",
       "      <th>performed_via_github_app</th>\n",
       "      <th>state_reason</th>\n",
       "      <th>draft</th>\n",
       "      <th>pull_request</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datasets</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>1754359316</td>\n",
       "      <td>I_kwDODunzps5okWYU</td>\n",
       "      <td>5947</td>\n",
       "      <td>Return the audio filename when decoding fails ...</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NONE</td>\n",
       "      <td>None</td>\n",
       "      <td>### Feature request\\r\\n\\r\\nReturn the audio fi...</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/huggingf...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datasets</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>1754234469</td>\n",
       "      <td>I_kwDODunzps5oj35l</td>\n",
       "      <td>5946</td>\n",
       "      <td>IndexError Not Solving -&gt; IndexError: Invalid ...</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NONE</td>\n",
       "      <td>None</td>\n",
       "      <td>### Describe the bug\\n\\nin &lt;cell line: 1&gt;:1   ...</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/huggingf...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datasets</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>1754084577</td>\n",
       "      <td>I_kwDODunzps5ojTTh</td>\n",
       "      <td>5945</td>\n",
       "      <td>Failing to upload dataset to the hub</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NONE</td>\n",
       "      <td>None</td>\n",
       "      <td>### Describe the bug\\n\\nTrying to upload a dat...</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/huggingf...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datasets</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://github.com/huggingface/datasets/pull/5944</td>\n",
       "      <td>1752882200</td>\n",
       "      <td>PR_kwDODunzps5Sx7O4</td>\n",
       "      <td>5944</td>\n",
       "      <td>Arrow dataset builder to be able to load and s...</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>CONTRIBUTOR</td>\n",
       "      <td>None</td>\n",
       "      <td>This adds a Arrow dataset builder to be able t...</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/huggingf...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/huggingf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datasets</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>1752824336</td>\n",
       "      <td>I_kwDODunzps5oefoQ</td>\n",
       "      <td>5943</td>\n",
       "      <td>Language `lzh` is not shown on the web interface</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NONE</td>\n",
       "      <td>None</td>\n",
       "      <td>### Describe the bug\\r\\n\\r\\nDespite its popula...</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/huggingf...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/datas...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://api.github.com/repos/huggingface/datas...   \n",
       "1  https://api.github.com/repos/huggingface/datas...   \n",
       "2  https://api.github.com/repos/huggingface/datas...   \n",
       "3  https://api.github.com/repos/huggingface/datas...   \n",
       "4  https://api.github.com/repos/huggingface/datas...   \n",
       "\n",
       "                                      repository_url  \\\n",
       "0  https://api.github.com/repos/huggingface/datasets   \n",
       "1  https://api.github.com/repos/huggingface/datasets   \n",
       "2  https://api.github.com/repos/huggingface/datasets   \n",
       "3  https://api.github.com/repos/huggingface/datasets   \n",
       "4  https://api.github.com/repos/huggingface/datasets   \n",
       "\n",
       "                                          labels_url  \\\n",
       "0  https://api.github.com/repos/huggingface/datas...   \n",
       "1  https://api.github.com/repos/huggingface/datas...   \n",
       "2  https://api.github.com/repos/huggingface/datas...   \n",
       "3  https://api.github.com/repos/huggingface/datas...   \n",
       "4  https://api.github.com/repos/huggingface/datas...   \n",
       "\n",
       "                                        comments_url  \\\n",
       "0  https://api.github.com/repos/huggingface/datas...   \n",
       "1  https://api.github.com/repos/huggingface/datas...   \n",
       "2  https://api.github.com/repos/huggingface/datas...   \n",
       "3  https://api.github.com/repos/huggingface/datas...   \n",
       "4  https://api.github.com/repos/huggingface/datas...   \n",
       "\n",
       "                                          events_url  \\\n",
       "0  https://api.github.com/repos/huggingface/datas...   \n",
       "1  https://api.github.com/repos/huggingface/datas...   \n",
       "2  https://api.github.com/repos/huggingface/datas...   \n",
       "3  https://api.github.com/repos/huggingface/datas...   \n",
       "4  https://api.github.com/repos/huggingface/datas...   \n",
       "\n",
       "                                            html_url          id  \\\n",
       "0  https://github.com/huggingface/datasets/issues...  1754359316   \n",
       "1  https://github.com/huggingface/datasets/issues...  1754234469   \n",
       "2  https://github.com/huggingface/datasets/issues...  1754084577   \n",
       "3  https://github.com/huggingface/datasets/pull/5944  1752882200   \n",
       "4  https://github.com/huggingface/datasets/issues...  1752824336   \n",
       "\n",
       "               node_id  number  \\\n",
       "0   I_kwDODunzps5okWYU    5947   \n",
       "1   I_kwDODunzps5oj35l    5946   \n",
       "2   I_kwDODunzps5ojTTh    5945   \n",
       "3  PR_kwDODunzps5Sx7O4    5944   \n",
       "4   I_kwDODunzps5oefoQ    5943   \n",
       "\n",
       "                                               title  ... closed_at  \\\n",
       "0  Return the audio filename when decoding fails ...  ...      None   \n",
       "1  IndexError Not Solving -> IndexError: Invalid ...  ...      None   \n",
       "2               Failing to upload dataset to the hub  ...      None   \n",
       "3  Arrow dataset builder to be able to load and s...  ...      None   \n",
       "4   Language `lzh` is not shown on the web interface  ...      None   \n",
       "\n",
       "  author_association active_lock_reason  \\\n",
       "0               NONE               None   \n",
       "1               NONE               None   \n",
       "2               NONE               None   \n",
       "3        CONTRIBUTOR               None   \n",
       "4               NONE               None   \n",
       "\n",
       "                                                body  \\\n",
       "0  ### Feature request\\r\\n\\r\\nReturn the audio fi...   \n",
       "1  ### Describe the bug\\n\\nin <cell line: 1>:1   ...   \n",
       "2  ### Describe the bug\\n\\nTrying to upload a dat...   \n",
       "3  This adds a Arrow dataset builder to be able t...   \n",
       "4  ### Describe the bug\\r\\n\\r\\nDespite its popula...   \n",
       "\n",
       "                                           reactions  \\\n",
       "0  {'url': 'https://api.github.com/repos/huggingf...   \n",
       "1  {'url': 'https://api.github.com/repos/huggingf...   \n",
       "2  {'url': 'https://api.github.com/repos/huggingf...   \n",
       "3  {'url': 'https://api.github.com/repos/huggingf...   \n",
       "4  {'url': 'https://api.github.com/repos/huggingf...   \n",
       "\n",
       "                                        timeline_url performed_via_github_app  \\\n",
       "0  https://api.github.com/repos/huggingface/datas...                     None   \n",
       "1  https://api.github.com/repos/huggingface/datas...                     None   \n",
       "2  https://api.github.com/repos/huggingface/datas...                     None   \n",
       "3  https://api.github.com/repos/huggingface/datas...                     None   \n",
       "4  https://api.github.com/repos/huggingface/datas...                     None   \n",
       "\n",
       "   state_reason  draft                                       pull_request  \n",
       "0          None    NaN                                                NaN  \n",
       "1          None    NaN                                                NaN  \n",
       "2          None    NaN                                                NaN  \n",
       "3          None  False  {'url': 'https://api.github.com/repos/huggingf...  \n",
       "4          None    NaN                                                NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe from all_issues list\n",
    "df = pd.DataFrame.from_records(all_issues)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded all the issues for datasets! Dataset saved at ..\\data/datasets-issues.jsonl\n"
     ]
    }
   ],
   "source": [
    "owner='huggingface'\n",
    "repo='datasets'\n",
    "num_issues=10_000\n",
    "rate_limit=5000\n",
    "issues_path=Path(\"../data\")\n",
    "df.to_json(f\"{issues_path}/{repo}-issues.jsonl\", orient='records', lines=True)\n",
    "print (f\"Downloaded all the issues for {repo}! Dataset saved at {issues_path}/{repo}-issues.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
