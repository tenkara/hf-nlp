{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/Raj/.cache/huggingface/datasets/rajknakka___parquet/rajknakka--github-issues-comments-d10cf254d383122f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'body', 'reactions', 'timeline_url', 'performed_via_github_app', 'state_reason', 'draft', 'pull_request', 'is_pull_request'],\n",
       "    num_rows: 4900\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load my recently created dataset from HuggingFace Datasets hub\n",
    "issues_dataset = load_dataset(\"rajknakka/github-issues-comments\", split=\"train\")\n",
    "issues_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Raj\\.cache\\huggingface\\datasets\\rajknakka___parquet\\rajknakka--github-issues-comments-d10cf254d383122f\\0.0.0\\2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\\cache-be07580daa56c5b4.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'body', 'reactions', 'timeline_url', 'performed_via_github_app', 'state_reason', 'draft', 'pull_request', 'is_pull_request'],\n",
       "    num_rows: 1598\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out pull requests as these tend to be rarely used for answering user queries and will introduce noise in our search engine\n",
    "issues_dataset = issues_dataset.filter(lambda row: row['is_pull_request'] == False and len(row[\"comments\"]) > 0)\n",
    "issues_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['html_url', 'title', 'comments', 'body'],\n",
       "    num_rows: 1598\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep the title, body, comments and html_url columns and remove the rest of the columns\n",
    "columns_to_keep = [\"title\", \"body\", \"comments\", \"html_url\"]\n",
    "columns = issues_dataset.column_names\n",
    "columns_to_remove = set(columns_to_keep).symmetric_difference(columns)\n",
    "prepared_dataset = issues_dataset.remove_columns(columns_to_remove)\n",
    "prepared_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'body', 'reactions', 'timeline_url', 'performed_via_github_app', 'state_reason', 'draft', 'pull_request', 'is_pull_request'],\n",
       "    num_rows: 1598\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create embeddings with the comments and their context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first conver the dataset to a pandas dataframe\n",
    "prepared_dataset.set_format(\"pandas\")\n",
    "issues_df = prepared_dataset[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi ! The audio data don\\'t always exist as files on disk - the blobs are often stored in the Arrow files. For now I\\'d suggest disabling decoding with `.cast_column(\"audio\", Audio(decode=False))` and apply your own decoding that handles corrupted files (maybe to filter them out ?)\\r\\n\\r\\ncc @sanchit-gandhi since it\\'s related to our discussion about allowing users to make decoding return `None` and show a warning when there are corrupted files',\n",
       " 'Thanks @lhoestq, I wasn\\'t aware of the decode flag. It makes more sense as you say to show a warning when there are corrupted files together with some metadata of the file that allows to filter them from the dataset.\\r\\n\\r\\nMy workaround was to catch the LibsndfileError and generate a dummy audio with an unsual sample rate to filter it later. However returning `None` seems better. \\r\\n\\r\\n`try:\\r\\n    array, sampling_rate = sf.read(file)\\r\\nexcept sf.LibsndfileError:\\r\\n    print(\"bad file\")\\r\\n    array = np.array([0.0])\\r\\n    sampling_rate = 99.000` \\r\\n\\r\\n']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the dataframe to see the four columns\n",
    "issues_df[\"comments\"][1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>html_url</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>Support for data with instance-wise dictionary...</td>\n",
       "      <td>Hi ! We use the Arrow columnar format under th...</td>\n",
       "      <td>### Feature request\\n\\nI notice that when load...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>Return the audio filename when decoding fails ...</td>\n",
       "      <td>Hi ! The audio data don't always exist as file...</td>\n",
       "      <td>### Feature request\\r\\n\\r\\nReturn the audio fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>Return the audio filename when decoding fails ...</td>\n",
       "      <td>Thanks @lhoestq, I wasn't aware of the decode ...</td>\n",
       "      <td>### Feature request\\r\\n\\r\\nReturn the audio fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://github.com/huggingface/datasets/issues...</td>\n",
       "      <td>IndexError Not Solving -&gt; IndexError: Invalid ...</td>\n",
       "      <td>https://colab.research.google.com/#scrollTo=AQ...</td>\n",
       "      <td>### Describe the bug\\n\\nin &lt;cell line: 1&gt;:1   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            html_url  \\\n",
       "0  https://github.com/huggingface/datasets/issues...   \n",
       "1  https://github.com/huggingface/datasets/issues...   \n",
       "2  https://github.com/huggingface/datasets/issues...   \n",
       "3  https://github.com/huggingface/datasets/issues...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Support for data with instance-wise dictionary...   \n",
       "1  Return the audio filename when decoding fails ...   \n",
       "2  Return the audio filename when decoding fails ...   \n",
       "3  IndexError Not Solving -> IndexError: Invalid ...   \n",
       "\n",
       "                                            comments  \\\n",
       "0  Hi ! We use the Arrow columnar format under th...   \n",
       "1  Hi ! The audio data don't always exist as file...   \n",
       "2  Thanks @lhoestq, I wasn't aware of the decode ...   \n",
       "3  https://colab.research.google.com/#scrollTo=AQ...   \n",
       "\n",
       "                                                body  \n",
       "0  ### Feature request\\n\\nI notice that when load...  \n",
       "1  ### Feature request\\r\\n\\r\\nReturn the audio fi...  \n",
       "2  ### Feature request\\r\\n\\r\\nReturn the audio fi...  \n",
       "3  ### Describe the bug\\n\\nin <cell line: 1>:1   ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explode the dataframe to have one row per comment\n",
    "comments_df = issues_df.explode(\"comments\", ignore_index=True)\n",
    "comments_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['html_url', 'title', 'comments', 'body'],\n",
       "    num_rows: 5650\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# done with pandas dataframe, convert back to HuggingFace dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "comments_dataset = Dataset.from_pandas(comments_df)\n",
    "comments_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
