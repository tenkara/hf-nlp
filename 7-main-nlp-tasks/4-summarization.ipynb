{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset amazon_reviews_multi (C:/Users/Raj/.cache/huggingface/datasets/amazon_reviews_multi/es/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0899ca88adb401e81ea64fe1c22353f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset amazon_reviews_multi (C:/Users/Raj/.cache/huggingface/datasets/amazon_reviews_multi/en/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9cc7f76bdc24d9eb3c9254e9aaf95eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 200000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "spanish_dataset = load_dataset(\"amazon_reviews_multi\", \"es\")\n",
    "english_dataset = load_dataset(\"amazon_reviews_multi\", \"en\")\n",
    "english_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\Raj\\.cache\\huggingface\\datasets\\amazon_reviews_multi\\en\\1.0.0\\724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\\cache-0b126a62dc97ecba.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>> Title: Worked in front position, not rear\n",
      "\n",
      "'>> Review: 3 stars because these are not rear brakes as stated in the item description. At least the mount adapter only worked on the front fork of the bike that I got it for.\n",
      "\n",
      "'>> Title: meh\n",
      "\n",
      "'>> Review: Does its job and its gorgeous but mine is falling apart, I had to basically put it together again with hot glue\n",
      "\n",
      "'>> Title: Can't beat these for the money\n",
      "\n",
      "'>> Review: Bought this for handling miscellaneous aircraft parts and hanger \"stuff\" that I needed to organize; it really fit the bill. The unit arrived quickly, was well packaged and arrived intact (always a good sign). There are five wall mounts-- three on the top and two on the bottom. I wanted to mount it on the wall, so all I had to do was to remove the top two layers of plastic drawers, as well as the bottom corner drawers, place it when I wanted and mark it; I then used some of the new plastic screw in wall anchors (the 50 pound variety) and it easily mounted to the wall. Some have remarked that they wanted dividers for the drawers, and that they made those. Good idea. My application was that I needed something that I can see the contents at about eye level, so I wanted the fuller-sized drawers. I also like that these are the new plastic that doesn't get brittle and split like my older plastic drawers did. I like the all-plastic construction. It's heavy duty enough to hold metal parts, but being made of plastic it's not as heavy as a metal frame, so you can easily mount it to the wall and still load it up with heavy stuff, or light stuff. No problem there. For the money, you can't beat it. Best one of these I've bought to date-- and I've been using some version of these for over forty years.\n"
     ]
    }
   ],
   "source": [
    "# let's sample the dataset\n",
    "def show_samples(dataset, num_samples=3, seed=42):\n",
    "    sample = dataset[\"train\"].shuffle(seed=seed).select(range(num_samples))\n",
    "    for example in sample:\n",
    "        print(f\"\\n'>> Title: {example['review_title']}\")\n",
    "        print(f\"\\n'>> Review: {example['review_body']}\")\n",
    "        \n",
    "show_samples(english_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_category\n",
       "home                      17679\n",
       "apparel                   15951\n",
       "wireless                  15717\n",
       "other                     13418\n",
       "beauty                    12091\n",
       "drugstore                 11730\n",
       "kitchen                   10382\n",
       "toy                        8745\n",
       "sports                     8277\n",
       "automotive                 7506\n",
       "lawn_and_garden            7327\n",
       "home_improvement           7136\n",
       "pet_products               7082\n",
       "digital_ebook_purchase     6749\n",
       "pc                         6401\n",
       "electronics                6186\n",
       "office_product             5521\n",
       "shoes                      5197\n",
       "grocery                    4730\n",
       "book                       3756\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training a summarization model on all 400k examples will take a long time on a single GPU.\n",
    "# Let's focus on a single domain of products\n",
    "\n",
    "english_dataset.set_format(\"pandas\")\n",
    "english_df = english_dataset[\"train\"][:]\n",
    "# show counts for top 20 product categories\n",
    "english_df[\"product_category\"].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's filter the dataset to only include examples from the \"Book\" and digital \"Ebook\" categories from both languages\n",
    "def filter_books(example):\n",
    "    return example[\"product_category\"] in [\"book\", \"digital_ebook_purchase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the filter to the dataset\n",
    "# before applying the filter, let's switch the format of english_dataset from \"pandas\" back to \"arrow\":\n",
    "english_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Raj\\.cache\\huggingface\\datasets\\amazon_reviews_multi\\es\\1.0.0\\724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\\cache-0ac36275c34e4cec.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Raj\\.cache\\huggingface\\datasets\\amazon_reviews_multi\\es\\1.0.0\\724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\\cache-adc33e5739600a83.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Raj\\.cache\\huggingface\\datasets\\amazon_reviews_multi\\es\\1.0.0\\724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\\cache-84ce11616b4cb2ad.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Raj\\.cache\\huggingface\\datasets\\amazon_reviews_multi\\en\\1.0.0\\724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\\cache-987e3f842ae71c25.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Raj\\.cache\\huggingface\\datasets\\amazon_reviews_multi\\en\\1.0.0\\724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\\cache-112c62204eaabee3.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Raj\\.cache\\huggingface\\datasets\\amazon_reviews_multi\\en\\1.0.0\\724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\\cache-84888e2548cef263.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\Raj\\.cache\\huggingface\\datasets\\amazon_reviews_multi\\en\\1.0.0\\724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\\cache-a65239a358049ce4.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>> Title: I'm dissapointed.\n",
      "\n",
      "'>> Review: I guess I had higher expectations for this book from the reviews. I really thought I'd at least like it. The plot idea was great. I loved Ash but, it just didnt go anywhere. Most of the book was about their radio show and talking to callers. I wanted the author to dig deeper so we could really get to know the characters. All we know about Grace is that she is attractive looking, Latino and is kind of a brat. I'm dissapointed.\n",
      "\n",
      "'>> Title: Good art, good price, poor design\n",
      "\n",
      "'>> Review: I had gotten the DC Vintage calendar the past two years, but it was on backorder forever this year and I saw they had shrunk the dimensions for no good reason. This one has good art choices but the design has the fold going through the picture, so it's less aesthetically pleasing, especially if you want to keep a picture to hang. For the price, a good calendar\n",
      "\n",
      "'>> Title: Helpful\n",
      "\n",
      "'>> Review: Nearly all the tips useful and. I consider myself an intermediate to advanced user of OneNote. I would highly recommend.\n"
     ]
    }
   ],
   "source": [
    "# apply the filter now\n",
    "spanish_books = spanish_dataset.filter(filter_books)\n",
    "english_books = english_dataset.filter(filter_books)\n",
    "show_samples(english_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\Raj\\.cache\\huggingface\\datasets\\amazon_reviews_multi\\en\\1.0.0\\724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\\cache-9679fdd8f546d5f1.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\Raj\\.cache\\huggingface\\datasets\\amazon_reviews_multi\\en\\1.0.0\\724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\\cache-0b9067c857222794.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\Raj\\.cache\\huggingface\\datasets\\amazon_reviews_multi\\en\\1.0.0\\724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\\cache-a653fea01d6b30cd.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\Raj\\.cache\\huggingface\\datasets\\amazon_reviews_multi\\en\\1.0.0\\724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\\cache-6cfc80feb0f00fd3.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>> Title: Easy to follow!!!!\n",
      "\n",
      "'>> Review: I loved The dash diet weight loss Solution. Never hungry. I would recommend this diet. Also the menus are well rounded. Try it. Has lots of the information need thanks.\n",
      "\n",
      "'>> Title: PARCIALMENTE DAADO\n",
      "\n",
      "'>> Review: Me lleg贸 el d铆a que tocaba, junto a otros libros que ped铆, pero la caja lleg贸 en mal estado lo cual da帽贸 las esquinas de los libros porque ven铆an sin protecci贸n (forro).\n",
      "\n",
      "'>> Title: no lo he podido descargar\n",
      "\n",
      "'>> Review: igual que el anterior\n"
     ]
    }
   ],
   "source": [
    "# create a bilingual dataset\n",
    "from datasets import DatasetDict, concatenate_datasets\n",
    "\n",
    "books_dataset = DatasetDict()\n",
    "\n",
    "for split in english_books.keys():\n",
    "    books_dataset[split] = concatenate_datasets([english_books[split], spanish_books[split]])\n",
    "    books_dataset[split] = books_dataset[split].shuffle(seed=42)\n",
    "    \n",
    "# let's check the number of examples in the training set\n",
    "show_samples(books_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Word Count Distribution'}, ylabel='Frequency'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the word count distribution in the books dataset\n",
    "import matplotlib.pyplot as plt\n",
    "books_dataset.set_format(\"pandas\")\n",
    "books_df = books_dataset[\"train\"][:]\n",
    "books_df[\"word_count\"] = books_df[\"review_body\"].apply(lambda x: len(x.split()))\n",
    "books_df[\"word_count\"].plot(kind=\"hist\", bins=100, title=\"Word Count Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the format of the dataset back to \"arrow\"\n",
    "books_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Raj\\.cache\\huggingface\\datasets\\amazon_reviews_multi\\en\\1.0.0\\724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\\cache-77effdc904843ac2.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Raj\\.cache\\huggingface\\datasets\\amazon_reviews_multi\\en\\1.0.0\\724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\\cache-7386f938fe7aa54b.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Raj\\.cache\\huggingface\\datasets\\amazon_reviews_multi\\en\\1.0.0\\724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\\cache-ecaa8a9e86b87984.arrow\n"
     ]
    }
   ],
   "source": [
    "# filter out any titles that are less than 2 words long\n",
    "books_dataset = books_dataset.filter(lambda x: len(x[\"review_body\"].split()) > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raj\\repos\\hf-nlp\\.venv\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load the tokenizer with the pretrained checkpoint\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"google/mt5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[30273,   261,  1037, 10990,   339, 64712,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test out the mt5 tokenizer on a small example:\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', ',', 'my', 'dog', 'is', 'cute', '</s>']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decode the tokenized inputs and see what the tokenizer does\n",
    "tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing inputs and targets with mt5 tokenizer using text_target to truncate the inputs and targets to a maximum length so they don't exceed the maximum context size of the model\n",
    "\n",
    "max_input_length = 512\n",
    "max_target_length = 30\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"review_body\"],\n",
    "        max_length=max_input_length,\n",
    "        truncation=True,\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        examples[\"review_title\"],\n",
    "        max_length=max_target_length,\n",
    "        truncation=True,\n",
    "    )\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Raj\\.cache\\huggingface\\datasets\\amazon_reviews_multi\\en\\1.0.0\\724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\\cache-9949e5342d363a6c.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Raj\\.cache\\huggingface\\datasets\\amazon_reviews_multi\\en\\1.0.0\\724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\\cache-8acedca0152688d1.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Raj\\.cache\\huggingface\\datasets\\amazon_reviews_multi\\en\\1.0.0\\724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\\cache-067fa938df9e0b81.arrow\n"
     ]
    }
   ],
   "source": [
    "# tokenize the whole corpus using the handy dataset.map() method\n",
    "# batched=True will ensure that the tokenization happens in batches on the CPU, multithreaded and fast tokenizers in hf transformers to get the most of the preprocessing\n",
    "tokenized_datasets = books_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commonly used metrics for summarization tasks are ROUGE and BLEU\n",
    "# suppose we want to compare the following two summaries:\n",
    "\n",
    "generated_summary = \"I absolutely loved reading the Hunger games\"\n",
    "reference_summary = \"I loved reading the Hunger games\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in c:\\users\\raj\\repos\\hf-nlp\\.venv\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\raj\\repos\\hf-nlp\\.venv\\lib\\site-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\raj\\repos\\hf-nlp\\.venv\\lib\\site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\raj\\repos\\hf-nlp\\.venv\\lib\\site-packages (from rouge_score) (1.24.3)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\raj\\repos\\hf-nlp\\.venv\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\raj\\repos\\hf-nlp\\.venv\\lib\\site-packages (from nltk->rouge_score) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\raj\\repos\\hf-nlp\\.venv\\lib\\site-packages (from nltk->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\raj\\repos\\hf-nlp\\.venv\\lib\\site-packages (from nltk->rouge_score) (2023.5.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\raj\\repos\\hf-nlp\\.venv\\lib\\site-packages (from nltk->rouge_score) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\raj\\repos\\hf-nlp\\.venv\\lib\\site-packages (from click->nltk->rouge_score) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# First install the rouge_score package\n",
    "! pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raj\\AppData\\Local\\Temp\\ipykernel_17872\\23820399.py:6: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library  Evaluate: https://huggingface.co/docs/evaluate\n",
      "  score1 = datasets.load_metric(\"rouge\")\n"
     ]
    }
   ],
   "source": [
    "# load the rouge metric\n",
    "import evaluate\n",
    "import datasets\n",
    "\n",
    "rouge_score = evaluate.load(\"rouge\")\n",
    "score1 = datasets.load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.923076923076923,\n",
       " 'rouge2': 0.7272727272727272,\n",
       " 'rougeL': 0.923076923076923,\n",
       " 'rougeLsum': 0.923076923076923}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the compute method to compute the rouge score at once\n",
    "scores = rouge_score.compute(\n",
    "    predictions=[generated_summary], references=[reference_summary], use_aggregator=True\n",
    ")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923), mid=Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923), high=Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.6666666666666666, recall=0.8, fmeasure=0.7272727272727272), mid=Score(precision=0.6666666666666666, recall=0.8, fmeasure=0.7272727272727272), high=Score(precision=0.6666666666666666, recall=0.8, fmeasure=0.7272727272727272)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923), mid=Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923), high=Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923), mid=Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923), high=Score(precision=0.8571428571428571, recall=1.0, fmeasure=0.923076923076923))}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rouge1 variant is the overlap of unigrams\n",
    "import pprint\n",
    "scores1 = score1.compute(\n",
    "    predictions=[generated_summary], references=[reference_summary], use_aggregator=True\n",
    ")\n",
    "scores1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a strong baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\raj\\repos\\hf-nlp\\.venv\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\raj\\repos\\hf-nlp\\.venv\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\raj\\repos\\hf-nlp\\.venv\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\raj\\repos\\hf-nlp\\.venv\\lib\\site-packages (from nltk) (2023.5.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\raj\\repos\\hf-nlp\\.venv\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\raj\\repos\\hf-nlp\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Raj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a common baseline for text summarization is to simply take the first three sentences of an article often called the laed-3 baseline. We could use full stops to track the sentence boundaries but this will fail on acronyms like \"U.S.A\" or \"U.K\". Instead, we can use the nltk library to split the text into sentences\n",
    "# download the punctuation rules\n",
    "import nltk\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the sentence tokenizer from nltk and create a simple function to extract the first 3 sentences in a review. The convention in text summarization is to separate each summary with a newline, so let's also include this and test it on a training example\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def three_sentence_summary(text):\n",
    "    return \"\\n\".join(sent_tokenize(text)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I gave it 4 stars because I felt the beginning chapter was a bit uneven, but as I got into the story, it gripped me.\n",
      "The characters, location, and the twists kept me reading well into the night.\n",
      "After posting this review, I'm going back to purchase the next book in the series.\n"
     ]
    }
   ],
   "source": [
    "print(three_sentence_summary(books_dataset[\"train\"][0][\"review_body\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now implement a function that extracts these summaries from a dataset and computes the ROUGE scores for the baseline\n",
    "\n",
    "def evaluate_baseline(dataset, metric):\n",
    "    summaries = [three_sentence_summary(review) for review in dataset[\"review_body\"]]\n",
    "    return metric.compute(predictions=summaries, references=dataset[\"review_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 11.69, 'rouge2': 5.79, 'rougeL': 11.01, 'rougeLsum': 11.17}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the baseline rouge score on the validation set and prettify them a bit using Pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "score = evaluate_baseline(books_dataset[\"validation\"], rouge_score)\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "rouge_dict = dict((rn, round(score[rn] * 100, 2)) for rn in rouge_names)\n",
    "rouge_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning mt5 with Trainer API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarization is a sequence to sequence task and hence loading the auto model for seq2seq\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6dc0f73d97474ea5041f95bacc9fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll need to generate summaries in order to compute ROUGE scores during training. \n",
    "\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "batch_size = 8\n",
    "num_train_epochs = 8\n",
    "\n",
    "# show the training loss with every epoch\n",
    "logging_steps = len(tokenized_datasets[\"train\"]) // batch_size\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir= f\"{model_name}-finetuned-amazon-en-es\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5.6e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    predict_with_generate=True,\n",
    "    logging_steps=logging_steps,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the metric that we want to use to evaluate the model\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    # Decode generated summaries into text\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    # Decode reference summaries into text\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    # compute the ROUGE scores\n",
    "    result = rouge_score.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    # Extract the median scores\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collator for seq2seq tasks will dynamically pad the inputs and labels\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see what this data collator produces when we feed it a batch of examples\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(\n",
    "    books_dataset[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 17606\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 423\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 442\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [336, 22161, 609, 419, 11236, 259, 3361, 336, 26766, 287, 259, 43909, 259, 39507, 639, 259, 262, 5485, 335, 25328, 261, 1156, 527, 336, 5666, 2387, 287, 9891, 261, 609, 259, 170946, 345, 416, 260, 486, 48971, 261, 8938, 261, 305, 287, 259, 71822, 263, 259, 49206, 416, 11807, 2857, 2387, 287, 9713, 260, 11076, 45217, 714, 4302, 261, 336, 277, 282, 259, 5846, 3004, 288, 17979, 287, 6844, 3435, 281, 287, 12614, 260, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [336, 277, 282, 66966, 345, 309, 1]}\n",
      "{'input_ids': [8204, 3435, 288, 4906, 332, 4205, 10608, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1], 'labels': [4983, 1059, 261, 1]}\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(tokenized_datasets[\"train\"][i])\n",
    "\n",
    "# features = (tokenized_datasets[\"train\"][i] for i in range(2))\n",
    "# features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   336,  22161,    609,    419,  11236,    259,   3361,    336,  26766,\n",
       "            287,    259,  43909,    259,  39507,    639,    259,    262,   5485,\n",
       "            335,  25328,    261,   1156,    527,    336,   5666,   2387,    287,\n",
       "           9891,    261,    609,    259, 170946,    345,    416,    260,    486,\n",
       "          48971,    261,   8938,    261,    305,    287,    259,  71822,    263,\n",
       "            259,  49206,    416,  11807,   2857,   2387,    287,   9713,    260,\n",
       "          11076,  45217,    714,   4302,    261,    336,    277,    282,    259,\n",
       "           5846,   3004,    288,  17979,    287,   6844,   3435,    281,    287,\n",
       "          12614,    260,      1],\n",
       "        [  8204,   3435,    288,   4906,    332,   4205,  10608,      1,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0]]), 'labels': tensor([[  336,   277,   282, 66966,   345,   309,     1],\n",
       "        [ 4983,  1059,   261,     1,  -100,  -100,  -100]]), 'decoder_input_ids': tensor([[    0,   336,   277,   282, 66966,   345,   309],\n",
       "        [    0,  4983,  1059,   261,     1,     0,     0]])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass the tokenized datasets to the data collator; sample the first couple of examples\n",
    "features = [tokenized_datasets[\"train\"][i] for i in range(2)]\n",
    "data_collator(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output, we have the expected results - \n",
    "1. Padding with 0 for PAD token to the right on the inputs of the second sample to be the same size as the longer first sample\n",
    "2. Labels padded with -100s to ensure the loss function ignores the padding tokens\n",
    "3. New decoder-input-ids which has shifted the labels to the right by inserting a [PAD] token in the first entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raj\\repos\\hf-nlp\\7-main-nlp-tasks\\mt5-small-finetuned-amazon-en-es is already a clone of https://huggingface.co/RajkNakka/mt5-small-finetuned-amazon-en-es. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "WARNING:huggingface_hub.repository:c:\\Users\\Raj\\repos\\hf-nlp\\7-main-nlp-tasks\\mt5-small-finetuned-amazon-en-es is already a clone of https://huggingface.co/RajkNakka/mt5-small-finetuned-amazon-en-es. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "# we have all the ingredients to instantiate the Trainer \n",
    "\n",
    "from transformers import Seq2SeqTrainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45aede1b47a444908cc58ae63f065f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 22.781015396118164,\n",
       " 'eval_rouge1': 0.106,\n",
       " 'eval_rouge2': 0.0,\n",
       " 'eval_rougeL': 0.106,\n",
       " 'eval_rougeLsum': 0.106,\n",
       " 'eval_runtime': 7.7337,\n",
       " 'eval_samples_per_second': 54.696,\n",
       " 'eval_steps_per_second': 6.853}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raj\\repos\\hf-nlp\\.venv\\Lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5dee2dadcb64ac38fb6b75a3a09a3a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.0643, 'learning_rate': 4.9003180372557925e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e87774ed1394875a22baa8569da730e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.180852174758911, 'eval_rouge1': 9.7343, 'eval_rouge2': 3.3747, 'eval_rougeL': 9.618, 'eval_rougeLsum': 9.5626, 'eval_runtime': 7.1873, 'eval_samples_per_second': 58.854, 'eval_steps_per_second': 7.374, 'epoch': 1.0}\n",
      "{'loss': 3.6469, 'learning_rate': 4.200636074511586e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b516f78cb6440a84b023eb3173f38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.0471205711364746, 'eval_rouge1': 10.6825, 'eval_rouge2': 3.6312, 'eval_rougeL': 10.6077, 'eval_rougeLsum': 10.6607, 'eval_runtime': 7.1909, 'eval_samples_per_second': 58.825, 'eval_steps_per_second': 7.37, 'epoch': 2.0}\n",
      "{'loss': 3.3978, 'learning_rate': 3.5009541117673784e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e21b41678a47218f5abe63580d6c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.9940688610076904, 'eval_rouge1': 11.3078, 'eval_rouge2': 4.3662, 'eval_rougeL': 11.2585, 'eval_rougeLsum': 11.1503, 'eval_runtime': 7.6058, 'eval_samples_per_second': 55.616, 'eval_steps_per_second': 6.968, 'epoch': 3.0}\n",
      "{'loss': 3.2626, 'learning_rate': 2.8012721490231714e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3ddd7b6b6248249fbaeaf6a78da738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.9707508087158203, 'eval_rouge1': 12.0216, 'eval_rouge2': 4.1979, 'eval_rougeL': 11.8896, 'eval_rougeLsum': 11.8944, 'eval_runtime': 7.6386, 'eval_samples_per_second': 55.377, 'eval_steps_per_second': 6.938, 'epoch': 4.0}\n",
      "{'loss': 3.1728, 'learning_rate': 2.101590186278964e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05c2dd527cc4b10bccac9d620a83408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.9692111015319824, 'eval_rouge1': 12.905, 'eval_rouge2': 4.8062, 'eval_rougeL': 12.8674, 'eval_rougeLsum': 12.8577, 'eval_runtime': 8.0505, 'eval_samples_per_second': 52.544, 'eval_steps_per_second': 6.583, 'epoch': 5.0}\n",
      "{'loss': 3.1046, 'learning_rate': 1.4019082235347571e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423041ff843745a0a0763d2582bea104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.9618046283721924, 'eval_rouge1': 13.3125, 'eval_rouge2': 5.7428, 'eval_rougeL': 13.2373, 'eval_rougeLsum': 13.223, 'eval_runtime': 8.1513, 'eval_samples_per_second': 51.894, 'eval_steps_per_second': 6.502, 'epoch': 6.0}\n",
      "{'loss': 3.069, 'learning_rate': 7.022262607905498e-06, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261f6e6c63784b8c916e1b6018599776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.96435546875, 'eval_rouge1': 13.8965, 'eval_rouge2': 6.0565, 'eval_rougeL': 13.9164, 'eval_rougeLsum': 13.8888, 'eval_runtime': 8.1893, 'eval_samples_per_second': 51.653, 'eval_steps_per_second': 6.472, 'epoch': 7.0}\n",
      "{'loss': 3.0409, 'learning_rate': 2.5442980463425713e-08, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf56f0499f14fad8f3cb694d75f67cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.9624009132385254, 'eval_rouge1': 13.5483, 'eval_rouge2': 5.8705, 'eval_rougeL': 13.4874, 'eval_rougeLsum': 13.5096, 'eval_runtime': 8.2422, 'eval_samples_per_second': 51.321, 'eval_steps_per_second': 6.43, 'epoch': 8.0}\n",
      "{'train_runtime': 2179.1772, 'train_samples_per_second': 64.634, 'train_steps_per_second': 8.08, 'train_loss': 3.594634968927913, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=17608, training_loss=3.594634968927913, metrics={'train_runtime': 2179.1772, 'train_samples_per_second': 64.634, 'train_steps_per_second': 8.08, 'train_loss': 3.594634968927913, 'epoch': 8.0})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cacc8e7efa8418d9e9ee21ade979ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/RajkNakka/mt5-small-finetuned-amazon-en-es\n",
      "   f9e3015..4cca43a  main -> main\n",
      "\n",
      "WARNING:huggingface_hub.repository:To https://huggingface.co/RajkNakka/mt5-small-finetuned-amazon-en-es\n",
      "   f9e3015..4cca43a  main -> main\n",
      "\n",
      "To https://huggingface.co/RajkNakka/mt5-small-finetuned-amazon-en-es\n",
      "   4cca43a..096f69c  main -> main\n",
      "\n",
      "WARNING:huggingface_hub.repository:To https://huggingface.co/RajkNakka/mt5-small-finetuned-amazon-en-es\n",
      "   4cca43a..096f69c  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/RajkNakka/mt5-small-finetuned-amazon-en-es/commit/4cca43ae2bea086b069ed7613a1315520915c714'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# push to the hub\n",
    "trainer.push_to_hub(commit_message=\"Training with HF Trainer complete\", tags=\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf800d4ac6543b7ad0a1b701a21cd67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.9624009132385254,\n",
       " 'eval_rouge1': 13.5483,\n",
       " 'eval_rouge2': 5.8705,\n",
       " 'eval_rougeL': 13.4874,\n",
       " 'eval_rougeLsum': 13.5096,\n",
       " 'eval_runtime': 8.2586,\n",
       " 'eval_samples_per_second': 51.219,\n",
       " 'eval_steps_per_second': 6.418,\n",
       " 'epoch': 8.0}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning mT5 with HF Accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataloader for each of our splits. Since the PyTorch dataloaders expect batches of tensors, we need to set the format to \"torch\" in our datasets\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a fresh version of the model from the hub\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"], collate_fn=data_collator, batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimizer\n",
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed the objects to the accelerator\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the learning rate scheduler\n",
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 10\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post processing to split the generated summaries into sentences separated by a newline in prep for input to the ROUGE metric\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # ROUGE expects a newline after each sentence\n",
    "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RajkNakka/mt5-finetuned-amazon-en-es-accelerate'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the HF repo\n",
    "from huggingface_hub import get_full_repo_name\n",
    "\n",
    "model_name = \"mt5-finetuned-amazon-en-es-accelerate\"\n",
    "repo_name = get_full_repo_name(model_name)\n",
    "repo_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/RajkNakka/mt5-finetuned-amazon-en-es-accelerate into local empty directory.\n",
      "WARNING:huggingface_hub.repository:Cloning https://huggingface.co/RajkNakka/mt5-finetuned-amazon-en-es-accelerate into local empty directory.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import Repository\n",
    "\n",
    "output_dir = \"results-mt5-finetuned-squad-accelerate\"\n",
    "repo = Repository(output_dir, clone_from=repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956cfeba355143cb841a88f6311b4772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22010 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raj\\repos\\hf-nlp\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:1346: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: {'rouge1': 1.175, 'rouge2': 0.3156, 'rougeL': 1.1769, 'rougeLsum': 1.1718}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding files tracked by Git LFS: ['tokenizer.json']. This may take a bit of time if the files are large.\n",
      "WARNING:huggingface_hub.repository:Adding files tracked by Git LFS: ['tokenizer.json']. This may take a bit of time if the files are large.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: {'rouge1': 4.3484, 'rouge2': 0.6079, 'rougeL': 4.332, 'rougeLsum': 4.3564}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "WARNING:huggingface_hub.repository:Several commits (2) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: {'rouge1': 4.8629, 'rouge2': 0.9547, 'rougeL': 4.8398, 'rougeLsum': 4.8711}\n",
      "Epoch 3: {'rouge1': 6.1173, 'rouge2': 1.0939, 'rougeL': 6.0525, 'rougeLsum': 6.0521}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "WARNING:huggingface_hub.repository:Several commits (2) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: {'rouge1': 6.869, 'rouge2': 1.9067, 'rougeL': 6.8625, 'rougeLsum': 6.9064}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (3) will be pushed upstream.\n",
      "WARNING:huggingface_hub.repository:Several commits (3) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: {'rouge1': 6.8872, 'rouge2': 2.1286, 'rougeL': 6.9101, 'rougeLsum': 6.9271}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (4) will be pushed upstream.\n",
      "WARNING:huggingface_hub.repository:Several commits (4) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: {'rouge1': 6.7466, 'rouge2': 1.9292, 'rougeL': 6.7217, 'rougeLsum': 6.7877}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (5) will be pushed upstream.\n",
      "WARNING:huggingface_hub.repository:Several commits (5) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: {'rouge1': 8.022, 'rouge2': 2.9509, 'rougeL': 8.0007, 'rougeLsum': 8.0849}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (6) will be pushed upstream.\n",
      "WARNING:huggingface_hub.repository:Several commits (6) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: {'rouge1': 8.6395, 'rouge2': 3.2542, 'rougeL': 8.5687, 'rougeLsum': 8.641}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (7) will be pushed upstream.\n",
      "WARNING:huggingface_hub.repository:Several commits (7) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: {'rouge1': 8.828, 'rouge2': 3.4601, 'rougeL': 8.7343, 'rougeLsum': 8.8272}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (8) will be pushed upstream.\n",
      "WARNING:huggingface_hub.repository:Several commits (8) will be pushed upstream.\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = accelerator.unwrap_model(model).generate(\n",
    "                batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "            )\n",
    "\n",
    "            generated_tokens = accelerator.pad_across_processes(\n",
    "                generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
    "            )\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            # If we did not pad to max length, we need to pad the labels too\n",
    "            labels = accelerator.pad_across_processes(\n",
    "                batch[\"labels\"], dim=1, pad_index=tokenizer.pad_token_id\n",
    "            )\n",
    "\n",
    "            generated_tokens = accelerator.gather(generated_tokens).cpu().numpy()\n",
    "            labels = accelerator.gather(labels).cpu().numpy()\n",
    "\n",
    "            # Replace -100 in the labels as we can't decode them\n",
    "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "            if isinstance(generated_tokens, tuple):\n",
    "                generated_tokens = generated_tokens[0]\n",
    "            decoded_preds = tokenizer.batch_decode(\n",
    "                generated_tokens, skip_special_tokens=True\n",
    "            )\n",
    "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "            decoded_preds, decoded_labels = postprocess_text(\n",
    "                decoded_preds, decoded_labels\n",
    "            )\n",
    "\n",
    "            rouge_score.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    # Compute metrics\n",
    "    result = rouge_score.compute()\n",
    "    # Extract the median ROUGE scores\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    print(f\"Epoch {epoch}:\", result)\n",
    "\n",
    "    # Save and upload\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "        repo.push_to_hub(\n",
    "            commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
